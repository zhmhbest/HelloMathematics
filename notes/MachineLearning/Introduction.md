<link rel='stylesheet' href='../../style/index.css'>
<script src='../../style/index.js'></script>

# [机器学习：导论](./index.html)

[TOC]

## 数据

### 特征

反映事件或对象在某方面的表现或性质的事项叫做 **特征（Feature）** 或 **属性（Attribute）**。

### 空间

#### 样本空间

由属性张成的空间即输入值的集合，叫做 **样本空间（Sample Space）** 或 **属性空间（Attribute Space）** 或 **输入空间**。
比如我们把西瓜的“色泽”、“根底”、“敲声”作为三个坐标轴，即组成了一个用于描述西瓜的三维空间。

#### 假设空间

在已知属性和属性可能取值的情况下，对所有可能满足目标的情况的一种毫无遗漏的假设集合。

#### 版本空间

我们把学习过程看作一个在所有假设组成的空间中进行搜索的过程。现实问题中，我们常面临很大的假设空间，但学习过程是基于有限样本训练集进行的，因此可能有多个假设与训练集一致，即存在一个与训练集一致的假设集合，称为**版本空间**。

### 数据划分

| | 特征值 | 目标值 |
| :-: | :-: | :-: |
| 训练集 | x_train | y_train
| 测试集 | x_test  | y_test

- **训练集**：用于得到模型
- **测试集**：测试模型准确率

## 训练

从数据中学得模型的过程叫做 **学习（Learning）** 或 **训练（Training）**。即寻找一个从样本空间到标记空间地一个映射，这一映射由模型来表示。

### 泛化能力

需要特别注意的是，学习得到的模型是为了能更好的适用于“新样本”，而不仅仅是在训练样本上工作得很好。模型对“新样本”的适用程度即称为**泛化能力**。

### 学习分类

| 特征值 | 目标值 | 学习类型 |
| :-: | :-: | :- |
| √ | √ | 监督学习（Supervised Learning）
| √ | × | 无监督学习（Unsupervised Learning）

### 问题分类

| 目标值 | 名称 |
| :-: | :- |
| 离散值 | 分类（Regression）
| 连续值 | 回归（Classification）
| × | 聚类（Clustering）

## 机器学习相关理论

### 丑小鸭定理

世界上不存在客观的分类标准，一切分类的标准都是主观的。

### 奥卡姆剃刀原则

若有多个假设与观察一致，则选最简单的那个。

### NFL定理

NFL（No Free Lunch Theorem），译为“没有免费的午餐”，即无论算法1多么聪明，算法2多么笨拙，它们的期望性能相同。该定理告诉我们，脱离具体问题，空泛地谈论什么算法更好毫无意义。

### 归纳偏置

我们经常会对一些问题做一些假设（归纳偏置）。比如：在KNN中，我假设特征空间中一个局部区域的大部分样本同属于一类；在NaiveBayes中，假设每个特征的条件概率相互独立（该假设也称为**先验**）。
